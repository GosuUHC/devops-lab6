version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:19092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 1
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
        reservations:
          cpus: "2"
          memory: 2G
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10

  redis:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.redis
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server /etc/redis/redis.conf
    volumes:
      - redis-data:/data
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 1G
        reservations:
          cpus: "1"
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  flink-jobmanager:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.flink
    container_name: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 4096m
        state.backend: hashmap
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
        parallelism.default: 8
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-savepoints:/opt/flink/savepoints
    networks:
      - bigdata-network
    depends_on:
      - kafka
      - redis
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
        reservations:
          cpus: "2"
          memory: 2G
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8081"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  flink-taskmanager:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.flink
    command: taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.memory.process.size: 8192m
        taskmanager.numberOfTaskSlots: 4
        state.backend: hashmap
        state.checkpoints.dir: file:///opt/flink/checkpoints
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-taskmanager-state:/opt/flink/state
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "8"
          memory: 16G
        reservations:
          cpus: "4"
          memory: 8G
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "6123"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  model-server:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.model-server
    container_name: model-server
    ports:
      - "8000:8000"
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      MODEL_PATH: /app/models
      PYTHONUNBUFFERED: 1
    volumes:
      - ./model-server:/app
      - ./data:/app/data:ro
    networks:
      - bigdata-network
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  bigdata-network:
    driver: bridge

volumes:
  redis-data:
    driver: local
  flink-checkpoints:
    driver: local
  flink-savepoints:
    driver: local
  flink-taskmanager-state:
    driver: local

