version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "19092:19092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:19092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 1
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
        reservations:
          cpus: "2"
          memory: 2G
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10

  redis:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.redis
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server /etc/redis/redis.conf
    volumes:
      - redis-data:/data
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 1G
        reservations:
          cpus: "1"
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  flink-jobmanager:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.flink
    container_name: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 4096m
        state.backend: hashmap
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
        parallelism.default: 8
        metrics.reporters: prom
        metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
        metrics.reporter.prom.port: 9250
        metrics.reporter.prom.host: 0.0.0.0
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-savepoints:/opt/flink/savepoints
    networks:
      - bigdata-network
    depends_on:
      - kafka
      - redis
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
        reservations:
          cpus: "2"
          memory: 2G
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8081"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  flink-taskmanager:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.flink
    command: taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.memory.process.size: 8192m
        taskmanager.numberOfTaskSlots: 4
        state.backend: hashmap
        state.checkpoints.dir: file:///opt/flink/checkpoints
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
        metrics.reporters: prom
        metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
        metrics.reporter.prom.port: 9250
        metrics.reporter.prom.host: 0.0.0.0
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - flink-taskmanager-state:/opt/flink/state
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "8"
          memory: 16G
        reservations:
          cpus: "4"
          memory: 8G
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "6123"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  model-server:
    build:
      context: .
      dockerfile: dockerfile-optimized/Dockerfile.model-server
    container_name: model-server
    ports:
      - "8000:8000"
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      MODEL_PATH: /app/models
      PYTHONUNBUFFERED: 1
    volumes:
      - ./model-server:/app
      - ./data:/app/data:ro
    networks:
      - bigdata-network
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  pushgateway:
    image: prom/pushgateway:latest
    container_name: pushgateway
    ports:
      - "9091:9091"
    command:
      - '--persistence.file=/tmp/pushgateway.db'
    networks:
      - bigdata-network
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/alerts.yml:/etc/prometheus/rules/alerts.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - bigdata-network
    depends_on:
      - pushgateway
      - flink-jobmanager
      - flink-taskmanager
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
        reservations:
          cpus: "1"
          memory: 2G
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_SERVER_ROOT_URL=http://localhost:3000
    volumes:
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    networks:
      - bigdata-network
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    restart: unless-stopped

  load-generator:
    build:
      context: .
      dockerfile: load-generator/Dockerfile
    container_name: load-generator
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:19092
      - KAFKA_TOPIC=transactions
      - EVENTS_PER_SECOND=1000
      - MODEL_SERVER_URL=http://model-server:8000/predict
      - PROMETHEUS_GATEWAY=pushgateway:9091
    networks:
      - bigdata-network
    depends_on:
      kafka:
        condition: service_started
      model-server:
        condition: service_started
      pushgateway:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M
        reservations:
          cpus: "0.5"
          memory: 256M
    restart: unless-stopped

networks:
  bigdata-network:
    driver: bridge

volumes:
  redis-data:
    driver: local
  flink-checkpoints:
    driver: local
  flink-savepoints:
    driver: local
  flink-taskmanager-state:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

